### Step 1: Create Namespace for users
```
kubectl create namespace nithya-namespace
```
### Step 2:To set a namespace explicitly for current context:
```
kubectl config set-context --current --namespace=nithya-namespace
```
#### Then verify:
```
kubectl config view --minify --output 'jsonpath={..namespace}'
```
![image](https://github.com/user-attachments/assets/02f1a0df-863a-47e3-b376-d9f0f30ba093)

### Step 3: Create a ServiceAccount for "User" in that namespace
```
kubectl create serviceaccount nithya-user -n nithya-namespace
```
![image](https://github.com/user-attachments/assets/2b673cf8-2534-44c2-81c5-147ac5b15d1b)

### Step 4:Deploy pods

#### 1.postgres-deployment
```
nano postgres-deployment.yaml
```
```
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: nithya-namespace
spec:
  type: ClusterIP
  ports:
    - port: 5432
  selector:
    app: postgres
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
  namespace: nithya-namespace
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
        - name: postgres
          image: postgres:13
          env:
            - name: POSTGRES_DB
              value: jasperdb
            - name: POSTGRES_USER
              value: jasper
            - name: POSTGRES_PASSWORD
              value: jasper123
          ports:
            - containerPort: 5432

```
#### Apply it.
```
kubectl apply -f postgres-deployment.yaml
```
#### 2.jasper report server

```
nano jasper-deployment.yaml
```
```
apiVersion: v1
kind: Service
metadata:
  name: jasperreports
  namespace: nithya-namespace
spec:
  type: NodePort
  ports:
    - port: 8080
      targetPort: 8080
      nodePort: 30080
  selector:
    app: jasperreports
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jasperreports
  namespace: nithya-namespace
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jasperreports
  template:
    metadata:
      labels:
        app: jasperreports
    spec:
      containers:
        - name: jasperreports
          image: bitnami/jasperreports:latest
          ports:
            - containerPort: 8080
          env:
            - name: JASPERREPORTS_DATABASE_TYPE
              value: postgresql
            - name: JASPERREPORTS_DATABASE_HOST
              value: postgres
            - name: JASPERREPORTS_DATABASE_PORT_NUMBER
              value: "5432"
            - name: JASPERREPORTS_DATABASE_NAME
              value: jasperdb
            - name: JASPERREPORTS_DATABASE_USER
              value: jasper
            - name: JASPERREPORTS_DATABASE_PASSWORD
              value: jasper123
            - name: JASPERREPORTS_USERNAME
              value: jasperadmin
            - name: JASPERREPORTS_PASSWORD
              value: jasperadmin
```
#### Apply it
```
kubectl apply -f jasper-deployment.yaml
```
- Check pods running in specific namespace

![image](https://github.com/user-attachments/assets/9f21acd4-3f6c-4943-8d63-987ce4f10b00)

### Step 5:Create a Role for namespace access (pods, services, etc)

```
nano nithya-role.yaml
```
```
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: nithya-namespace
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]

```
Apply it.
```
kubectl apply -f nithya-role.yaml
```
### Step 6: Bind the Role to User's ServiceAccount
```
nano nithya-rolebinding.yaml
```
```
kind: RoleBinding
metadata:
  name: nithya-rolebinding
  namespace: nithya-namespace
subjects:
- kind: ServiceAccount
  name: nithya
  namespace: nithya-namespace
  # apiGroup: rbac.authorization.k8s.io   <--- REMOVE THIS LINE
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io
```
Apply it.
```
kubectl apply -f nithya-rolebinding.yaml
```
### Step 7: Get the Token for the ServiceAccount (Kubernetes 1.24+)
```
kubectl create token nithya-user -n nithya-namespace
```
### Step 8: Get cluster details
Get the current context name:
```
kubectl config current-context
```
![image](https://github.com/user-attachments/assets/f2f9d222-5eb9-49ab-b8f1-a7e9b5fecb44)

### Step 9:Get the cluster info:
- Replace **NAME** with your cluster name from the context above
```
kubectl config view --raw -o jsonpath='{.clusters[?(@.name == "NAME")].cluster.server}'
```
![image](https://github.com/user-attachments/assets/8d2c91c1-bda5-401c-862b-bffe27f338b4)

### Step10: Also, get the cluster CA (Base64 encoded):
```
kubectl config view --raw -o jsonpath='{.clusters[?(@.name == "test-cluster")].cluster.certificate-authority-data}'
```
### Step 11:Manually Create Kubeconfig File
```
nano nithya-kubeconfig.manuall 
```
```
apiVersion: v1
kind: Config
clusters:
- name: test-cluster
  cluster:
    server: <CLUSTER_API_URL>
    certificate-authority-data: <BASE64_CA_DATA>
contexts:
- name: nithya-context
  context:
    cluster: test-cluster
    namespace: nithya-namespace
    user: nithya-user
current-context: nithya-context
users:
- name: nithya-user
  user:
    token: <YOUR_TOKEN_FROM_STEP_7>
```
### Step 12: Test the Config
```
KUBECONFIG=./nithya-kubeconfig.manuall kubectl get pods -n nithya-namespace
```
![image](https://github.com/user-attachments/assets/b8824023-4682-482a-896b-283e32473d5a)

### Step 13: Test from other namespace,it should fail.

![image](https://github.com/user-attachments/assets/702a4966-ae1f-4e43-959e-0d5fafd0bbac)

### (Not recommended): Create kubeconfig file automatically

#### "az aks get-credentials" directly, it may fetch "admin credentials" ,so  it connects with all namespace

- Connects to the AKS cluster test-cluster in resource group rg-ranjitha.

- Downloads the cluster credentials and writes them to ./kubeconfig-yaml.

- Sets the current context inside that file so you can run kubectl commands using it.
```
az aks get-credentials --resource-group <resoursegroup-name> --name <cluster-name> --file ./<kubeconfig-filename>
```
![image](https://github.com/user-attachments/assets/3f2c8e9c-0ca4-4aa7-b874-1a2df3cb3d61)

#### Auto-generated kubeconfig file looks like
```
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUU2VENDQXRHZ0F3SUJBZ0lSQU0wVXA2Q3M4QnlJSzU1TTU4YUhRM2d3RFFZSktvWklodmNOQVFFTEJRQXcKRFRFTE1Ba0dBMVVFQXhNQ1kyRXdJQmNOTWpVd05URTFNRFV6T1RRMl>
    server: https://test-cluster-dns-yh6r89d2.hcp.centralindia.azmk8s.io:443
  name: test-cluster
contexts:
- context:
    cluster: test-cluster
    user: clusterUser_rg-ranjitha_test-cluster
    namespace: nithya-namespace      ### Specify the namespace.
  name: test-cluster
current-context: test-cluster
kind: Config
preferences: {}
users:
- name: clusterUser_rg-ranjitha_test-cluster
  user:
    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUZIVENDQXdXZ0F3SUJBZ0lRWkptUWQvbTNjTzV1bk1RQnZhWThKREFOQmdrcWhraUc5dzBCQVFzRkFEQU4KTVFzd0NRWURWUVFERXdKallUQWVGdzB5TlRBMU1UVXdOVE01TkRaYUZ3M>
    client-key-data: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlKS1FJQkFBS0NBZ0VBLzFFVmZWTjlndEJTdFN0aFRGbUgvdlpBZjRWNXZkbnQxbmxKMXdHOHA4eUp6NnpRCmV3ZHdVOXdOT2ZDWFJFenFSRTNhb3ZxaGpqVU9PblIybk1NTk8wU2pmWnM3Y>
    token: ojk466aijnikb50jhursz995cpm6hbsam1ip0m97u4plm7xmqpu4xiywg2fdkxjtmo3n86f5i1b7nd209fraqlczmz5ywf2jggtucayrd4tpupw8jokv0ukzvk6pmg2w
```
- Send the kubeconfig file to user.
- After Downloading user can access
```
KUBECONFIG=./<file-name> kubectl get pods
```
![image](https://github.com/user-attachments/assets/05c276f0-56b0-4cf2-8988-0f22fb6268b0)
![image](https://github.com/user-attachments/assets/cb5ca998-a948-4d2e-adf5-5b91a6b4c7b7)

